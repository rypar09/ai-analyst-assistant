{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157e0d0d-e9e4-4106-abce-08555a2a9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AAPL...\n",
      "10-K Filing URL: https://www.sec.gov/Archives/edgar/data/320193/000032019324000123/aapl-20240928.htm\n",
      "  Extracting section 1 (business)...\n",
      "    Saved business section.\n",
      "  Extracting section 1A (risk_factors)...\n",
      "    Saved risk_factors section.\n",
      "  Extracting section 7 (mdna)...\n",
      "    Saved mdna section.\n"
     ]
    }
   ],
   "source": [
    "from sec_api import QueryApi, ExtractorApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Initialize SEC API\n",
    "load_dotenv()\n",
    "sec_api_key = os.getenv(\"SEC_API_KEY\")\n",
    "queryApi = QueryApi(api_key=sec_api_key)\n",
    "extractorApi = ExtractorApi(api_key=sec_api_key)\n",
    "\n",
    "# List of tickers to process\n",
    "# tickers = ['AAPL', 'MSFT', 'NVDA', 'GOOGL', 'AMZN', 'CRM', 'SNOW', 'PLTR', 'AMD', 'META']\n",
    "tickers = ['AAPL']\n",
    "\n",
    "# Base folder for section outputs\n",
    "base_folder = '10k_sections'\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "# Sections to extract: {section_number: label}\n",
    "sections = {\n",
    "    \"1\": \"business\",\n",
    "    \"1A\": \"risk_factors\",\n",
    "    \"7\": \"mdna\",\n",
    "}\n",
    "\n",
    "# Get latest 10-K filing for each ticker in the list\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nProcessing {ticker}...\")\n",
    "    try:\n",
    "        # Query most recent 10-K\n",
    "        query = {\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                    \"query\": f\"{ticker} AND formType:\\\"10-K\\\"\"\n",
    "                }\n",
    "            },\n",
    "            \"from\": \"0\",\n",
    "            \"size\": \"1\",\n",
    "            \"sort\": [{\"filedAt\": {\"order\": \"desc\"}}]\n",
    "        }\n",
    "    \n",
    "        response = queryApi.get_filings(query)\n",
    "        filing_url = response['filings'][0]['linkToFilingDetails']\n",
    "        print(f\"10-K Filing URL: {filing_url}\")\n",
    "\n",
    "        # Make subfolder for ticker\n",
    "        ticker_folder = os.path.join(base_folder, ticker)\n",
    "        os.makedirs(ticker_folder, exist_ok=True)\n",
    "        \n",
    "        for section_num, label in sections.items():\n",
    "            try:\n",
    "                print(f\"  Extracting section {section_num} ({label})...\")\n",
    "                section_text = extractorApi.get_section(filing_url, section_num)\n",
    "                output_path = os.path.join(ticker_folder, f\"{label}.txt\")\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(section_text)\n",
    "                print(f\"    Saved {label} section.\")\n",
    "            except Exception as sec_err:\n",
    "                print(f\"    Failed to extract section {section_num}: {sec_err}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed for {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "396c721f-6913-4b7b-af14-ea3a29853696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate text to fit GPT-3.5-turbo token limits\n",
    "def truncate(text, max_words=3000):\n",
    "    return ' '.join(text.split()[:max_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a4d279b-320f-412d-882b-7c1562e182bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing report for AAPL...\n",
      "  Word count for AAPL: 6453 words\n",
      "  Full report saved for AAPL.\n",
      "  Investment brief saved for AAPL.\n",
      "\n",
      " Total words summarized across all tickers: 6453\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Initialize Open AI API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Folder where MD&A texts were saved\n",
    "sections_folder = '10k_sections'\n",
    "\n",
    "# Output folders\n",
    "briefs_folder = 'investment_briefs'\n",
    "full_reports_folder = 'full_reports'\n",
    "os.makedirs(briefs_folder, exist_ok=True)\n",
    "os.makedirs(full_reports_folder, exist_ok=True)\n",
    "\n",
    "# To track word count summarized\n",
    "total_word_count = 0\n",
    "\n",
    "# Use OpenAI to summarize\n",
    "def generate_research_report(business_text, risk_text, mdna_text, ticker):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial analyst assistant. Respond in clear, concise, professional writing.\"},       # tells the model who it is and how to behave\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Write a detailed equity research report on {ticker} based on the sections provided from its latest 10-K filing.\n",
    "\n",
    "**Strict formatting rules:**\n",
    "- Do NOT use any Markdown symbols (no *, **, #, -, or bullets).\n",
    "- Do NOT use headings or numbered lists.\n",
    "- Use plain paragraph text only.\n",
    "- Write in clear, professional prose, using proper paragraph breaks for each section.\n",
    "\n",
    "The report will be inserted directly into a Microsoft Word document.\n",
    "\n",
    "Use the following structure:\n",
    "\n",
    "1. Basic Information — Include placeholders:\n",
    "   - Ticker: {ticker}\n",
    "   - Exchange: [insert exchange]\n",
    "   - Sector / Industry: [insert sector and industry]\n",
    "   - Stock Price: [insert]\n",
    "   - Market Cap: [insert]\n",
    "   - Target Price: [insert]\n",
    "   - Float / Liquidity: [insert]\n",
    "   - Major Shareholders: [insert]\n",
    "\n",
    "2. Business Description — Summarize the company’s operations, products/services, revenue drivers, and operating model based on the 10-K.\n",
    "\n",
    "3. Industry Overview & Competitive Positioning — Provide a general overview of the industry and where the company fits. Note: use [insert industry insights here] as a placeholder if needed.\n",
    "\n",
    "4. Investment Summary — Include significant developments and company outlook. Do not include a Buy/Hold/Sell rating; instead, write: [insert investment recommendation here].\n",
    "\n",
    "5. Valuation — Use a placeholder to note this will be added manually:\n",
    "   [insert valuation summary with methods and key ratios]\n",
    "\n",
    "6. Financial Analysis — Summarize recent financial performance and notable trends. Include any accounting quirks or nonrecurring items mentioned in the MD&A.\n",
    "\n",
    "7. Investment Risks — Describe major risks the company faces, using what's provided in the 10-K.\n",
    "\n",
    "8. Environmental, Social, and Governance (ESG) — Provide a paragraph summarizing ESG-related disclosures if available. Otherwise, write: [insert ESG overview].\n",
    "\n",
    "9. Analyst Commentary — Placeholder for your personal judgment:\n",
    "   [insert your brief commentary on thesis, conviction level, or flags]\n",
    "\n",
    "Here are the source materials:\n",
    "\n",
    "- Business Description:\n",
    "{business_text}\n",
    "\n",
    "- Risk Factors:\n",
    "{risk_text}\n",
    "\n",
    "- MD&A:\n",
    "{mdna_text}\n",
    "\"\"\"}                    # tells the model what to do\n",
    "            ]\n",
    "        )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Generate investment brief\n",
    "def generate_investment_brief(full_report, ticker):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial analyst assistant. Respond in clear, concise, professional writing.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Write a one-page investment brief for {ticker} based on the following full-length equity research report. Do not use bullet points or Markdown formatting. Write 2 to 4 clear, objective paragraphs in flowing prose.\n",
    "\n",
    "Focus on:\n",
    "- A high-level overview of the company's business and operations\n",
    "- Key recent developments or strategic moves\n",
    "- Summary of financial performance or trends mentioned\n",
    "- Major risks or areas of concern\n",
    "- Forward-looking observations (e.g., expected challenges or momentum)\n",
    "\n",
    "Do not include a Buy/Hold/Sell recommendation or subjective opinions. The brief should be informative and professional, suitable for internal use or to hand to a portfolio manager.\n",
    "\n",
    "{full_report}\n",
    "\"\"\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "# Main Processing\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nProcessing report for {ticker}...\")\n",
    "    try:\n",
    "        ticker_folder = os.path.join(sections_folder, ticker)\n",
    "        \n",
    "        # Read all 4 sections\n",
    "        with open(os.path.join(ticker_folder, \"business.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            business_text = f.read()\n",
    "        with open(os.path.join(ticker_folder, \"risk_factors.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            risk_text = f.read()\n",
    "        with open(os.path.join(ticker_folder, \"mdna.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            mdna_text = f.read()\n",
    "\n",
    "        business_text = truncate(business_text, max_words=2000)\n",
    "        risk_text = truncate(risk_text, max_words=2000)\n",
    "        # mdna_text = truncate(mdna_text, max_words=4000)\n",
    "        \n",
    "        # Word count tracking (if using gpt-4-turbo, no need to truncate)\n",
    "        section_word_count = sum(len(section.split()) for section in [business_text, risk_text, mdna_text])\n",
    "        total_word_count += section_word_count\n",
    "        print(f\"  Word count for {ticker}: {section_word_count} words\")\n",
    "\n",
    "        # Generate full report\n",
    "        full_report = generate_research_report(business_text, risk_text, mdna_text, ticker)\n",
    "        with open(os.path.join(full_reports_folder, f\"{ticker}_full_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_report)\n",
    "        print(f\"  Full report saved for {ticker}.\")\n",
    "\n",
    "        # Generate investment brief\n",
    "        brief = generate_investment_brief(full_report, ticker)\n",
    "        with open(os.path.join(briefs_folder, f\"{ticker}_brief.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(brief)\n",
    "        print(f\"  Investment brief saved for {ticker}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to process {ticker}: {e}\")\n",
    "\n",
    "print(f\"\\n Total words summarized across all tickers: {total_word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30935cf3-1e77-4f36-8dd0-bdb02abb873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted: AAPL_full_report.txt → AAPL Full Report.docx\n",
      "✅ Converted: AAPL_brief.txt → AAPL Investment Brief.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "import os\n",
    "\n",
    "\n",
    "def txt_to_docx(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        txt_path = os.path.join(folder_path, filename)\n",
    "        ticker = filename.split(\"_\")[0]\n",
    "\n",
    "        # Name Word file based on type\n",
    "        docx_filename = f\"{ticker} Investment Brief.docx\" if 'brief' in filename else f\"{ticker} Full Report.docx\"\n",
    "        docx_path = os.path.join(folder_path, docx_filename)\n",
    "\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        doc = Document()\n",
    "\n",
    "        # Title heading\n",
    "        title = doc.add_heading(docx_filename.replace(\".docx\", \"\"), level=0)\n",
    "        title.alignment = WD_ALIGN_PARAGRAPH.LEFT\n",
    "\n",
    "        for paragraph_text in content.split(\"\\n\\n\"):\n",
    "            if paragraph_text.strip():\n",
    "                p = doc.add_paragraph(paragraph_text.strip())\n",
    "                run = p.runs[0]\n",
    "                run.font.name = 'Times New Roman'\n",
    "                run.font.size = Pt(12)\n",
    "                p.alignment = WD_ALIGN_PARAGRAPH.LEFT\n",
    "\n",
    "        doc.save(docx_path)\n",
    "        print(f\"✅ Converted: {filename} → {docx_filename}\")\n",
    "\n",
    "# Run on both folders\n",
    "txt_to_docx('full_reports')\n",
    "txt_to_docx('investment_briefs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
